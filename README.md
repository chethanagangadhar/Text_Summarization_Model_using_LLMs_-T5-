# Text_Summarization_Model_using_LLMs_-T5-

•	Developed a text summarization model using the T5 model to generate concise and accurate summaries from lengthy text.
•	Utilized Hugging Face’s transformers library for tokenizing input text and preparing it for processing by the model.
•	Fine-tuned model parameters such as beam search (num_beams=4) and length penalty (length_penalty=2.0) to optimize summary quality.
•	Applied advanced techniques to achieve high-quality, domain-specific summaries with minimal computation time.
•	Integrated Python code for seamless tokenization, summarization, and output decoding, improving text processing efficiency.
•	Achieved a 20-30% improvement in readability, coherence, and overall summary quality compared to traditional methods.
•	Tools and libraries used: Python, Hugging Face's transformers, T5, PyTorch, TensorFlow.
